{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skimage\n",
    "from skimage.util import random_noise\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function was written by a computer vision course instructors \n",
    "def show_images(images, titles):\n",
    "    #This function is used to show image(s) with titles by sending an array of images and an array of associated titles.\n",
    "    # images[0] will be drawn with the title titles[0] if exists\n",
    "    # You aren't required to understand this function, use it as-is.\n",
    "    assert len(images) == len(titles)\n",
    "    for title in titles:\n",
    "        cv2.namedWindow(title, cv2.WINDOW_NORMAL)\n",
    "    \n",
    "    for title, img in zip(titles, images):\n",
    "        cv2.imshow(title, img)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# How to use show_images([list of images], [list of titles]) They must have the same length\n",
    "# show_images([img1, img2], ['This is image 1', 'This is image 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_median_filter(image: np.array, kernel_size: int):\n",
    "    denoised_image = cv2.medianBlur(skimage.img_as_uint(image),kernel_size)\n",
    "    return denoised_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_negative_transform(img: np.array):\n",
    "    imgTransformed = 255-img\n",
    "    return imgTransformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_stretch(img: np.array):\n",
    "    stretchedImg= (img - np.min(img))/(np.max(img)-np.min(img))\n",
    "    return stretchedImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma_correction(img: np.array, c: float ,lamda : float ):\n",
    "    img =skimage.img_as_float(img)\n",
    "    correctedImg= c*(img**lamda)\n",
    "    return correctedImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_equalization(img: np.array):\n",
    "    equalizedImg = cv2.equalizeHist(img)\n",
    "    return equalizedImg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function was written by a computer vision course instructors \n",
    "def popularity_quantization(img: np.ndarray, number_of_colors: int) -> np.ndarray:\n",
    "    assert number_of_colors > 1\n",
    "    assert len(img.shape) == 3\n",
    "               \n",
    "    # Get the most popular color\n",
    "    colors, counts = np.unique(img.reshape(-1, 3), return_counts = True, axis = 0)\n",
    "    sorted_indicies = np.flip(np.argsort(counts))\n",
    "    sorted_colors = colors[sorted_indicies]\n",
    "    selected_colors = sorted_colors[:number_of_colors]\n",
    "    # Get the nearest color for the pixel using Least square distance\n",
    "    color_distance = np.sqrt(np.sum((np.expand_dims(img.reshape(-1, 3), axis=1) - selected_colors) ** 2, axis=2))\n",
    "    indicies_of_the_least_distance = np.argmin(color_distance, axis=1)\n",
    "    new_img = selected_colors[indicies_of_the_least_distance].reshape(img.shape)\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noisy images\n",
    "img = cv2.imread('./assets/original.png', cv2.IMREAD_GRAYSCALE)\n",
    "img = skimage.img_as_float(img)\n",
    "n1 = random_noise(img, mode='s&p', clip=False, amount=0.02)\n",
    "n2 = random_noise(img, mode='s&p', clip=False, amount=0.04)\n",
    "n3 = random_noise(img, mode='s&p', clip=False, amount=0.08)\n",
    "show_images([n1,n2,n3],['n1','n2','n3'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# median filter\n",
    "n1_denoised=apply_median_filter(n1,3)\n",
    "n2_denoised=apply_median_filter(n2,3)\n",
    "n3_denoised=apply_median_filter(n3,3)\n",
    "show_images([n1_denoised,n2_denoised,n3_denoised],['denoise_n1','denoise_n2','denoise_n3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative transform test\n",
    "img = cv2.imread('./assets/negative.png', cv2.IMREAD_GRAYSCALE)\n",
    "imgTransformed=apply_negative_transform(img)\n",
    "show_images([img,imgTransformed],['img','imgTransformed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear stretch test \n",
    "darkImg = cv2.imread('./assets/dark.png', cv2.IMREAD_GRAYSCALE)\n",
    "badKidImg = cv2.imread('./assets/bad_kid.tif', cv2.IMREAD_GRAYSCALE)\n",
    "darkImgLinearStretch = linear_stretch(darkImg)\n",
    "badKidImgLinearStretch = linear_stretch(badKidImg)\n",
    "\n",
    "show_images([darkImg,badKidImg,darkImgLinearStretch,badKidImgLinearStretch],['darkImg','badKidImg','darkImgLinearStretch','badKidImgLinearStretch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram equalization test \n",
    "darkImg = cv2.imread('./assets/dark.png', cv2.IMREAD_GRAYSCALE)\n",
    "badKidImg = cv2.imread('./assets/bad_kid.tif', cv2.IMREAD_GRAYSCALE)\n",
    "darkImgEqualized = histogram_equalization(darkImg)\n",
    "badKidImgEqualized = histogram_equalization(badKidImg)\n",
    "show_images([darkImg,badKidImg,darkImgEqualized,badKidImgEqualized],['darkImg','badKidImg','darkImgEqualized','badKidImgEqualized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# popularity quantization algorithim test \n",
    "#500 seems to be a reasonable number to capture the image details \n",
    "imgWithColors = cv2.imread('./assets/image_with_colors.png')\n",
    "imgWithColors = skimage.img_as_float(imgWithColors)\n",
    "imgWithColorsQuantized = popularity_quantization(imgWithColors,500)\n",
    "imgWithColorsQuantized = skimage.img_as_uint(imgWithColorsQuantized)\n",
    "show_images([imgWithColors,imgWithColorsQuantized],['imgWithColors','imgWithColorsQuantized'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the advantage of popularity algorithm over uniform quantization is that it distributes the existing colors to colors from whithin the image instead of distributing the colors to uniform ones that may not exist in the image and having a noticable conturing effect. But the popularity algorithms does not address colors with low popularity although theses colors may be significant. The median cut addresed that issue by representing each group of colors by a color from within the group so no color get ignored as in the case of the popularity algorithm  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
